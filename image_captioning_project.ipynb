{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_captioning_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzhang15/computer_vision_project/blob/master/image_captioning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXheOktoFkCF"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jktcJq8K0pS",
        "outputId": "fcf4e361-bb94-4618-939a-1aeac2fae3d6"
      },
      "source": [
        "# this is just trying to follow a tutorial on RNN\n",
        "text = ['hey how are you', 'good i am fine', 'have a nice day']\n",
        "\n",
        "chars =set(''.join(text))\n",
        "print(chars)\n",
        "\n",
        "int2char = dict(enumerate(chars))\n",
        "print(int2char)\n",
        "\n",
        "char2int = {char: ind for ind, char in int2char.items()}\n",
        "print(char2int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'h', ' ', 'o', 'y', 'm', 'f', 'i', 'u', 'v', 'w', 'd', 'e', 'c', 'n', 'a', 'g', 'r'}\n",
            "{0: 'h', 1: ' ', 2: 'o', 3: 'y', 4: 'm', 5: 'f', 6: 'i', 7: 'u', 8: 'v', 9: 'w', 10: 'd', 11: 'e', 12: 'c', 13: 'n', 14: 'a', 15: 'g', 16: 'r'}\n",
            "{'h': 0, ' ': 1, 'o': 2, 'y': 3, 'm': 4, 'f': 5, 'i': 6, 'u': 7, 'v': 8, 'w': 9, 'd': 10, 'e': 11, 'c': 12, 'n': 13, 'a': 14, 'g': 15, 'r': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az8XrdiAMQQL"
      },
      "source": [
        "The project breaks down to 4 parts. \n",
        "mRNN model:\n",
        "1. embeding layer: neural net (v -> 128)\n",
        "2. embeding layer: neural net (128 -> 256) + activation\n",
        "  - weight is randomly initialized\n",
        "3. Recurrent layer\n",
        "  - r(t) = ReLU(weight * r(t - 1) + w(t)) where w(t) is the word representation and r(t - 1) is mapped into the same vector space as w(t)\n",
        "4. Multimodal layer:\n",
        "  - m(t) = g2(V_w * w(t) + V_r * r(t) + V_I * I) where g2 = 1.7159 * tanh(2/3 x)\n",
        "5. final layer: neural net (512 -> M) + softmax\n",
        "\n",
        "\n",
        "Pre-process Data:\n",
        "\n",
        "Train:\n",
        "\n",
        "Validate:"
      ]
    }
  ]
}